odps.project.name=df_cb_125003
odps.end.point=http://service.cn.maxcompute.aliyun.com/api
odps.runtime.end.point = http://service.cn-beijing-vpc.maxcompute.aliyun-inc.com/api



spark.driver.cores = 2
spark.driver.memory = 2g
#spark.executor.instances = 2
spark.dynamicAllocation.shuffleTracking.enabled = true
spark.dynamicAllocation.shuffleTracking.timeout = 20s
spark.dynamicAllocation.enabled = true
spark.dynamicAllocation.maxExecutors = 10
spark.dynamicAllocation.initialExecutors = 2
spark.executor.cores = 1
spark.executor.memory = 4g

spark.eventLog.enabled = true
spark.eventLog.overwrite = true
spark.eventLog.dir = odps://admin_task_project/cupidhistory/sparkhistory

spark.sql.catalogImplementation = odps
spark.sql.sources.default = hive

spark.sql.odps.columnarReaderBatchSize=4096
spark.sql.odps.enableVectorizedReader=True
spark.sql.odps.enableVectorizedWriter=True
spark.sql.odps.split.size=256 MB


spark.hadoop.odps.cpuid.webproxy.endpoint = http://service.cn.maxcompute.aliyun
spark.hadoop.odps.moye.trackurl.host  = http://jobview.odps.aliyun.com

odps.cpuid.webproxy.endpoint = http://service.cn.maxcompute.aliyun
odps.moye.trackurl.host  = http://jobview.odps.aliyun.com